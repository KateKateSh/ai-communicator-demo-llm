import streamlit as st
import json
from pathlib import Path
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM

# –ü—É—Ç—å –∫ prompt-—à–∞–±–ª–æ–Ω—É
PROMPT_PATH = Path("prompts/event_template.txt")

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-small")
    model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-small")
    return pipeline("text2text-generation", model=model, tokenizer=tokenizer)

llm_pipeline = load_model()

def ai_response_with_llm(event_text: str) -> str:
    prompt_template = PROMPT_PATH.read_text(encoding="utf-8")
    input_text = f"{prompt_template}\n\n–°–æ–±—ã—Ç–∏–µ: {event_text}"
    result = llm_pipeline(input_text, max_new_tokens=256)[0]["generated_text"]
    return result

# Streamlit UI
st.set_page_config(page_title="AI-–∫–æ–º–º—É–Ω–∏–∫–∞—Ç–æ—Ä —Å–ø—Ä–æ—Åa. LLM demo", layout="centered")
st.title("ü§ñ AI-–∫–æ–º–º—É–Ω–∏–∫–∞—Ç–æ—Ä —Å–ø—Ä–æ—Å–∞. LLM demo")

event_text = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Å–æ–±—ã—Ç–∏–µ", placeholder="–ü—Ä–∏–º–µ—Ä: 14 —Ñ–µ–≤—Ä–∞–ª—è –≤ –ú–æ—Å–∫–≤–µ —Å–Ω–µ–≥ + –∞–∫—Ü–∏—è –Ω–∞ —Ü–≤–µ—Ç—ã")

if st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"):
    if not event_text.strip():
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è.")
    else:
        st.markdown("‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º...")
        result = ai_response_with_llm(event_text)
        st.markdown(result)
